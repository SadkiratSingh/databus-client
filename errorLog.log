0    [ScalaTest-main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.107.105 instead (on interface enp0s31f6)
1    [ScalaTest-main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
32   [ScalaTest-main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
261  [ScalaTest-main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
402  [ScalaTest-main] INFO  org.apache.spark.SparkContext  - Submitted application: Triple reader
463  [ScalaTest-main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
463  [ScalaTest-main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
464  [ScalaTest-main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
464  [ScalaTest-main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
465  [ScalaTest-main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
745  [ScalaTest-main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 40139.
765  [ScalaTest-main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
781  [ScalaTest-main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
784  [ScalaTest-main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
784  [ScalaTest-main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
828  [ScalaTest-main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-2ec7f3fc-9fa8-4d7b-b393-88f3f8b7359c
849  [ScalaTest-main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 4.0 GB
862  [ScalaTest-main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
926  [ScalaTest-main] INFO  org.spark_project.jetty.util.log  - Logging initialized @1537ms
979  [ScalaTest-main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
990  [ScalaTest-main] INFO  org.spark_project.jetty.server.Server  - Started @1603ms
1004 [ScalaTest-main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@51a06cbe{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
1004 [ScalaTest-main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
1022 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c8b96ec{/jobs,null,AVAILABLE,@Spark}
1022 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4d157787{/jobs/json,null,AVAILABLE,@Spark}
1023 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@68ed96ca{/jobs/job,null,AVAILABLE,@Spark}
1024 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3228d990{/jobs/job/json,null,AVAILABLE,@Spark}
1024 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54e7391d{/stages,null,AVAILABLE,@Spark}
1025 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@50b8ae8d{/stages/json,null,AVAILABLE,@Spark}
1025 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@255990cc{/stages/stage,null,AVAILABLE,@Spark}
1026 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@29d2d081{/stages/stage/json,null,AVAILABLE,@Spark}
1027 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@40e4ea87{/stages/pool,null,AVAILABLE,@Spark}
1028 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@58783f6c{/stages/pool/json,null,AVAILABLE,@Spark}
1028 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3a7b503d{/storage,null,AVAILABLE,@Spark}
1029 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@512d92b{/storage/json,null,AVAILABLE,@Spark}
1029 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@62c5bbdc{/storage/rdd,null,AVAILABLE,@Spark}
1030 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7bdf6bb7{/storage/rdd/json,null,AVAILABLE,@Spark}
1031 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1bc53649{/environment,null,AVAILABLE,@Spark}
1031 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@88d6f9b{/environment/json,null,AVAILABLE,@Spark}
1032 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d93e0d{/executors,null,AVAILABLE,@Spark}
1032 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@475b7792{/executors/json,null,AVAILABLE,@Spark}
1033 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@751e664e{/executors/threadDump,null,AVAILABLE,@Spark}
1033 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@160c3ec1{/executors/threadDump/json,null,AVAILABLE,@Spark}
1038 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@182b435b{/static,null,AVAILABLE,@Spark}
1038 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@610db97e{/,null,AVAILABLE,@Spark}
1039 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6f0628de{/api,null,AVAILABLE,@Spark}
1040 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4ced35ed{/jobs/job/kill,null,AVAILABLE,@Spark}
1040 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2c22a348{/stages/stage/kill,null,AVAILABLE,@Spark}
1042 [ScalaTest-main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://pop-os.lan:4040
1100 [ScalaTest-main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
1143 [ScalaTest-main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44295.
1143 [ScalaTest-main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on pop-os.lan:44295
1145 [ScalaTest-main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
1163 [ScalaTest-main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, pop-os.lan, 44295, None)
1165 [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager pop-os.lan:44295 with 4.0 GB RAM, BlockManagerId(driver, pop-os.lan, 44295, None)
1166 [ScalaTest-main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, pop-os.lan, 44295, None)
1167 [ScalaTest-main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, pop-os.lan, 44295, None)
1283 [ScalaTest-main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7b208b45{/metrics/json,null,AVAILABLE,@Spark}
1862 [ScalaTest-main] WARN  org.apache.spark.sql.SparkSession$Builder  - Using an existing SparkSession; some configuration may not take effect.
13639 [Executor task launch worker for task 1554] ERROR org.apache.jena.riot  - [line: 1, col: 1 ] Expected BNode or IRI: Got: [DIRECTIVE:prefix]
13641 [Executor task launch worker for task 1554] ERROR org.apache.spark.executor.Executor  - Exception in task 0.0 in stage 29.0 (TID 1554)
org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Expected BNode or IRI: Got: [DIRECTIVE:prefix]
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:147)
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:148)
	at org.apache.jena.riot.lang.LangEngine.exceptionDirect(LangEngine.java:143)
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:137)
	at org.apache.jena.riot.lang.LangNTuple.checkIRIOrBNode(LangNTuple.java:89)
	at org.apache.jena.riot.lang.LangNTriples.parseOne(LangNTriples.java:74)
	at org.apache.jena.riot.lang.LangNTriples.parseOne(LangNTriples.java:38)
	at org.apache.jena.riot.lang.LangNTuple.next(LangNTuple.java:67)
	at org.apache.jena.atlas.iterator.IteratorResourceClosing.next(IteratorResourceClosing.java:77)
	at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:394)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)
	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
13659 [task-result-getter-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Lost task 0.0 in stage 29.0 (TID 1554, localhost, executor driver): org.apache.jena.riot.RiotException: [line: 1, col: 1 ] Expected BNode or IRI: Got: [DIRECTIVE:prefix]
	at org.apache.jena.riot.system.ErrorHandlerFactory$ErrorHandlerStd.fatal(ErrorHandlerFactory.java:147)
	at org.apache.jena.riot.lang.LangEngine.raiseException(LangEngine.java:148)
	at org.apache.jena.riot.lang.LangEngine.exceptionDirect(LangEngine.java:143)
	at org.apache.jena.riot.lang.LangEngine.exception(LangEngine.java:137)
	at org.apache.jena.riot.lang.LangNTuple.checkIRIOrBNode(LangNTuple.java:89)
	at org.apache.jena.riot.lang.LangNTriples.parseOne(LangNTriples.java:74)
	at org.apache.jena.riot.lang.LangNTriples.parseOne(LangNTriples.java:38)
	at org.apache.jena.riot.lang.LangNTuple.next(LangNTuple.java:67)
	at org.apache.jena.atlas.iterator.IteratorResourceClosing.next(IteratorResourceClosing.java:77)
	at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
	at scala.collection.Iterator$$anon$10.next(Iterator.scala:394)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)
	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1364)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

13660 [task-result-getter-1] ERROR org.apache.spark.scheduler.TaskSetManager  - Task 0 in stage 29.0 failed 1 times; aborting job
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
3    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
34   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
198  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
311  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
367  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
368  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
368  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
368  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
369  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
701  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 45779.
722  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
738  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
741  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
741  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
749  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-0913e9b4-96bb-4108-a1c4-f9c8078f7dda
764  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
776  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
841  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3781ms
891  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
906  [main] INFO  org.spark_project.jetty.server.Server  - Started @3847ms
921  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@4c7e978c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
921  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
938  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d23296{/jobs,null,AVAILABLE,@Spark}
939  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/jobs/json,null,AVAILABLE,@Spark}
939  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/jobs/job,null,AVAILABLE,@Spark}
940  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job/json,null,AVAILABLE,@Spark}
941  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages,null,AVAILABLE,@Spark}
941  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/json,null,AVAILABLE,@Spark}
942  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/stage,null,AVAILABLE,@Spark}
943  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/stages/stage/json,null,AVAILABLE,@Spark}
944  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/stages/pool,null,AVAILABLE,@Spark}
944  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/pool/json,null,AVAILABLE,@Spark}
945  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/storage,null,AVAILABLE,@Spark}
946  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/storage/json,null,AVAILABLE,@Spark}
947  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage/rdd,null,AVAILABLE,@Spark}
947  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/rdd/json,null,AVAILABLE,@Spark}
948  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/environment,null,AVAILABLE,@Spark}
949  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/environment/json,null,AVAILABLE,@Spark}
950  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/executors,null,AVAILABLE,@Spark}
950  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/executors/json,null,AVAILABLE,@Spark}
951  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors/threadDump,null,AVAILABLE,@Spark}
952  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/threadDump/json,null,AVAILABLE,@Spark}
960  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/static,null,AVAILABLE,@Spark}
960  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/,null,AVAILABLE,@Spark}
962  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/api,null,AVAILABLE,@Spark}
962  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@655a01d8{/jobs/job/kill,null,AVAILABLE,@Spark}
963  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c29fe36{/stages/stage/kill,null,AVAILABLE,@Spark}
965  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
1029 [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
1104 [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45761.
1104 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:45761
1106 [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
1126 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 45761, None)
1129 [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:45761 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 45761, None)
1131 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 45761, None)
1131 [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 45761, None)
1275 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7cfac39f{/metrics/json,null,AVAILABLE,@Spark}
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
3    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
30   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
168  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
261  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
303  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
304  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
304  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
304  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
305  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
610  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 41251.
628  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
641  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
643  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
643  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
649  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-65387bcd-7aad-4f7b-9c51-57b4847ca08b
663  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
672  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
726  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3719ms
770  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
783  [main] INFO  org.spark_project.jetty.server.Server  - Started @3777ms
796  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@3bd6ba24{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
796  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@78b612c6{/jobs,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3fd9e827{/jobs/json,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4e682398{/jobs/job,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@24a86066{/jobs/job/json,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/stages,null,AVAILABLE,@Spark}
814  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/stages/json,null,AVAILABLE,@Spark}
814  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@58d6b7b9{/stages/stage,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/stage/json,null,AVAILABLE,@Spark}
816  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/pool,null,AVAILABLE,@Spark}
816  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c101cc1{/stages/pool/json,null,AVAILABLE,@Spark}
817  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7d0d91a1{/storage,null,AVAILABLE,@Spark}
817  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/storage/json,null,AVAILABLE,@Spark}
818  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/storage/rdd,null,AVAILABLE,@Spark}
818  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/storage/rdd/json,null,AVAILABLE,@Spark}
819  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/environment,null,AVAILABLE,@Spark}
819  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/environment/json,null,AVAILABLE,@Spark}
820  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/executors,null,AVAILABLE,@Spark}
820  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/executors/json,null,AVAILABLE,@Spark}
821  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/executors/threadDump,null,AVAILABLE,@Spark}
821  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/executors/threadDump/json,null,AVAILABLE,@Spark}
827  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/static,null,AVAILABLE,@Spark}
827  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@22a10ac6{/,null,AVAILABLE,@Spark}
828  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@12fe1f28{/api,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/jobs/job/kill,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@51d719bc{/stages/stage/kill,null,AVAILABLE,@Spark}
831  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
887  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
947  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35445.
948  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:35445
949  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
968  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 35445, None)
970  [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:35445 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 35445, None)
972  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 35445, None)
972  [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 35445, None)
1116 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@64942607{/metrics/json,null,AVAILABLE,@Spark}
1695 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
1    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
28   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
167  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
269  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
313  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
313  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
313  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
313  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
314  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
622  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 35123.
639  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
652  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
654  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
654  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
661  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-bfa73fb3-4d61-4847-a01e-3ddec6b7d149
674  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
683  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
736  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3681ms
781  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
793  [main] INFO  org.spark_project.jetty.server.Server  - Started @3739ms
805  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@2a8a4e0c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
806  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
822  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@38e7ed69{/jobs,null,AVAILABLE,@Spark}
822  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1ef9d6{/jobs/json,null,AVAILABLE,@Spark}
823  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@17461db{/jobs/job,null,AVAILABLE,@Spark}
824  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4e682398{/jobs/job/json,null,AVAILABLE,@Spark}
824  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@670b3ca{/stages,null,AVAILABLE,@Spark}
825  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@24a86066{/stages/json,null,AVAILABLE,@Spark}
826  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/stages/stage,null,AVAILABLE,@Spark}
827  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/stages/stage/json,null,AVAILABLE,@Spark}
828  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages/pool,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/pool/json,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/storage,null,AVAILABLE,@Spark}
830  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c101cc1{/storage/json,null,AVAILABLE,@Spark}
831  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7d0d91a1{/storage/rdd,null,AVAILABLE,@Spark}
831  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/storage/rdd/json,null,AVAILABLE,@Spark}
832  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/environment,null,AVAILABLE,@Spark}
833  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/environment/json,null,AVAILABLE,@Spark}
833  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/executors,null,AVAILABLE,@Spark}
834  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/executors/json,null,AVAILABLE,@Spark}
835  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/executors/threadDump,null,AVAILABLE,@Spark}
836  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/executors/threadDump/json,null,AVAILABLE,@Spark}
843  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/static,null,AVAILABLE,@Spark}
844  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7f37b6d9{/,null,AVAILABLE,@Spark}
845  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@71e35c4{/api,null,AVAILABLE,@Spark}
846  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@26fb4d06{/jobs/job/kill,null,AVAILABLE,@Spark}
846  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/stages/stage/kill,null,AVAILABLE,@Spark}
848  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
912  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
984  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35749.
985  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:35749
986  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
1005 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 35749, None)
1007 [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:35749 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 35749, None)
1009 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 35749, None)
1009 [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 35749, None)
1142 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5f05c8d6{/metrics/json,null,AVAILABLE,@Spark}
1874 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4153 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4189 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4205 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4222 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4227 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4234 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4272 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4277 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4286 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4295 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4867 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5215 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
3    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
29   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
163  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
264  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
307  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
307  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
307  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
307  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
308  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
603  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 37677.
620  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
633  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
635  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
635  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
642  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-56cb8eff-d9fc-454a-82d0-abdb024ae5b2
655  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
664  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
717  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3871ms
761  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
773  [main] INFO  org.spark_project.jetty.server.Server  - Started @3929ms
785  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@4c7e978c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
785  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d23296{/jobs,null,AVAILABLE,@Spark}
802  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/jobs/json,null,AVAILABLE,@Spark}
802  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/jobs/job,null,AVAILABLE,@Spark}
803  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job/json,null,AVAILABLE,@Spark}
803  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages,null,AVAILABLE,@Spark}
803  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/json,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/stage,null,AVAILABLE,@Spark}
805  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/stages/stage/json,null,AVAILABLE,@Spark}
805  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/stages/pool,null,AVAILABLE,@Spark}
806  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/pool/json,null,AVAILABLE,@Spark}
806  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/storage,null,AVAILABLE,@Spark}
807  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/storage/json,null,AVAILABLE,@Spark}
807  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage/rdd,null,AVAILABLE,@Spark}
808  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/rdd/json,null,AVAILABLE,@Spark}
808  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/environment,null,AVAILABLE,@Spark}
809  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/environment/json,null,AVAILABLE,@Spark}
809  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/executors,null,AVAILABLE,@Spark}
810  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/executors/json,null,AVAILABLE,@Spark}
810  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors/threadDump,null,AVAILABLE,@Spark}
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/threadDump/json,null,AVAILABLE,@Spark}
816  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/static,null,AVAILABLE,@Spark}
817  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/,null,AVAILABLE,@Spark}
818  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/api,null,AVAILABLE,@Spark}
818  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@655a01d8{/jobs/job/kill,null,AVAILABLE,@Spark}
819  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c29fe36{/stages/stage/kill,null,AVAILABLE,@Spark}
820  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
876  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
935  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38483.
936  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:38483
937  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
956  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 38483, None)
958  [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:38483 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 38483, None)
960  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 38483, None)
960  [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 38483, None)
1091 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7cfac39f{/metrics/json,null,AVAILABLE,@Spark}
1821 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4125 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4170 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4188 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4206 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4214 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4221 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4284 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4287 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4294 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4300 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4730 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5077 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
1    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
28   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
165  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
265  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
307  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
307  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
307  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
307  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
308  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
593  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 42225.
610  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
623  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
625  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
625  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
632  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-393686c1-9fb7-437d-b8de-7040e96e6ec3
645  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
654  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
708  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3706ms
750  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
763  [main] INFO  org.spark_project.jetty.server.Server  - Started @3763ms
775  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@4c7e978c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
775  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
791  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d23296{/jobs,null,AVAILABLE,@Spark}
792  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/jobs/json,null,AVAILABLE,@Spark}
792  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/jobs/job,null,AVAILABLE,@Spark}
793  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job/json,null,AVAILABLE,@Spark}
794  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages,null,AVAILABLE,@Spark}
795  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/json,null,AVAILABLE,@Spark}
795  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/stage,null,AVAILABLE,@Spark}
797  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/stages/stage/json,null,AVAILABLE,@Spark}
797  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/stages/pool,null,AVAILABLE,@Spark}
798  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/pool/json,null,AVAILABLE,@Spark}
799  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/storage,null,AVAILABLE,@Spark}
799  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/storage/json,null,AVAILABLE,@Spark}
800  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage/rdd,null,AVAILABLE,@Spark}
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/rdd/json,null,AVAILABLE,@Spark}
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/environment,null,AVAILABLE,@Spark}
802  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/environment/json,null,AVAILABLE,@Spark}
803  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/executors,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/executors/json,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors/threadDump,null,AVAILABLE,@Spark}
805  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/threadDump/json,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/static,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/,null,AVAILABLE,@Spark}
814  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/api,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@655a01d8{/jobs/job/kill,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c29fe36{/stages/stage/kill,null,AVAILABLE,@Spark}
817  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
885  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
951  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46067.
952  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:46067
953  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
972  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 46067, None)
974  [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:46067 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 46067, None)
976  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 46067, None)
976  [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 46067, None)
1120 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7cfac39f{/metrics/json,null,AVAILABLE,@Spark}
1834 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4118 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4153 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4170 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4187 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4194 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4201 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4259 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4262 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4268 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4275 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4745 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5108 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
1    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
30   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
166  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
252  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
296  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
296  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
296  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
297  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
297  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
597  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 34493.
614  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
628  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
630  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
630  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
637  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-716933b1-54ec-493e-8b9b-e5991e6a1878
650  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
660  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
716  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3714ms
760  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
772  [main] INFO  org.spark_project.jetty.server.Server  - Started @3771ms
784  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@4c7e978c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
784  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d23296{/jobs,null,AVAILABLE,@Spark}
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/jobs/json,null,AVAILABLE,@Spark}
802  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/jobs/job,null,AVAILABLE,@Spark}
803  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job/json,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/json,null,AVAILABLE,@Spark}
805  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/stage,null,AVAILABLE,@Spark}
806  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/stages/stage/json,null,AVAILABLE,@Spark}
807  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/stages/pool,null,AVAILABLE,@Spark}
808  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/pool/json,null,AVAILABLE,@Spark}
808  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/storage,null,AVAILABLE,@Spark}
809  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/storage/json,null,AVAILABLE,@Spark}
810  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage/rdd,null,AVAILABLE,@Spark}
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/rdd/json,null,AVAILABLE,@Spark}
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/environment,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/environment/json,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/executors,null,AVAILABLE,@Spark}
814  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/executors/json,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors/threadDump,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/threadDump/json,null,AVAILABLE,@Spark}
823  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/static,null,AVAILABLE,@Spark}
824  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/,null,AVAILABLE,@Spark}
825  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/api,null,AVAILABLE,@Spark}
826  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@655a01d8{/jobs/job/kill,null,AVAILABLE,@Spark}
826  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c29fe36{/stages/stage/kill,null,AVAILABLE,@Spark}
828  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
893  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
976  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39027.
976  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:39027
977  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
997  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 39027, None)
999  [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:39027 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 39027, None)
1001 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 39027, None)
1002 [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 39027, None)
1137 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7cfac39f{/metrics/json,null,AVAILABLE,@Spark}
1841 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4132 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4172 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4191 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4225 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4230 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4236 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4271 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4274 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4281 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4287 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4751 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5094 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
1    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
29   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
165  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
265  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
308  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
308  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
308  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
309  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
309  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
606  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 44555.
623  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
636  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
638  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
638  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
645  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-7bdbd34d-a508-4edb-a535-8a6d0ce024f6
658  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
667  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
723  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3846ms
769  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
781  [main] INFO  org.spark_project.jetty.server.Server  - Started @3906ms
794  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@4c7e978c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
794  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d23296{/jobs,null,AVAILABLE,@Spark}
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/jobs/json,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/jobs/job,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job/json,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/json,null,AVAILABLE,@Spark}
814  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/stage,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/stages/stage/json,null,AVAILABLE,@Spark}
815  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/stages/pool,null,AVAILABLE,@Spark}
816  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/pool/json,null,AVAILABLE,@Spark}
816  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/storage,null,AVAILABLE,@Spark}
817  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/storage/json,null,AVAILABLE,@Spark}
817  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage/rdd,null,AVAILABLE,@Spark}
818  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/rdd/json,null,AVAILABLE,@Spark}
818  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/environment,null,AVAILABLE,@Spark}
819  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/environment/json,null,AVAILABLE,@Spark}
819  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/executors,null,AVAILABLE,@Spark}
820  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/executors/json,null,AVAILABLE,@Spark}
821  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors/threadDump,null,AVAILABLE,@Spark}
821  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/threadDump/json,null,AVAILABLE,@Spark}
827  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/static,null,AVAILABLE,@Spark}
828  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/api,null,AVAILABLE,@Spark}
830  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@655a01d8{/jobs/job/kill,null,AVAILABLE,@Spark}
830  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c29fe36{/stages/stage/kill,null,AVAILABLE,@Spark}
831  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
892  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
965  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42805.
966  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:42805
967  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
986  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 42805, None)
988  [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:42805 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 42805, None)
990  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 42805, None)
990  [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 42805, None)
1139 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7cfac39f{/metrics/json,null,AVAILABLE,@Spark}
1860 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4224 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4265 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4284 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4314 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4319 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4325 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4360 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4364 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4371 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4377 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4825 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5166 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
1    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
27   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
165  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
263  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
305  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
305  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
305  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
306  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
306  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
619  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 41603.
635  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
648  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
650  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
650  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
657  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-7c69e558-5768-481f-9a47-08e2e2d24d9a
670  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
679  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
737  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3792ms
781  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
793  [main] INFO  org.spark_project.jetty.server.Server  - Started @3848ms
805  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@22ebccb9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
805  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
822  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@376c7d7d{/jobs,null,AVAILABLE,@Spark}
823  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@58d6b7b9{/jobs/json,null,AVAILABLE,@Spark}
824  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job,null,AVAILABLE,@Spark}
825  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/jobs/job/json,null,AVAILABLE,@Spark}
825  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages,null,AVAILABLE,@Spark}
826  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c101cc1{/stages/json,null,AVAILABLE,@Spark}
826  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7d0d91a1{/stages/stage,null,AVAILABLE,@Spark}
828  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/stage/json,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/stages/pool,null,AVAILABLE,@Spark}
829  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/stages/pool/json,null,AVAILABLE,@Spark}
830  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage,null,AVAILABLE,@Spark}
831  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/json,null,AVAILABLE,@Spark}
831  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/storage/rdd,null,AVAILABLE,@Spark}
832  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/storage/rdd/json,null,AVAILABLE,@Spark}
833  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/environment,null,AVAILABLE,@Spark}
833  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/environment/json,null,AVAILABLE,@Spark}
834  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors,null,AVAILABLE,@Spark}
835  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/json,null,AVAILABLE,@Spark}
836  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/executors/threadDump,null,AVAILABLE,@Spark}
836  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e6d4780{/executors/threadDump/json,null,AVAILABLE,@Spark}
843  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@650ae78c{/static,null,AVAILABLE,@Spark}
844  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@51d719bc{/,null,AVAILABLE,@Spark}
846  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d38edfd{/api,null,AVAILABLE,@Spark}
846  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6614bd4b{/jobs/job/kill,null,AVAILABLE,@Spark}
847  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4d266391{/stages/stage/kill,null,AVAILABLE,@Spark}
849  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
922  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
997  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46589.
998  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:46589
999  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
1018 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 46589, None)
1021 [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:46589 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 46589, None)
1023 [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 46589, None)
1024 [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 46589, None)
1166 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@50eb4a2c{/metrics/json,null,AVAILABLE,@Spark}
1942 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4268 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4303 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4319 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4337 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4342 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4348 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4383 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4386 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4395 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4404 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4926 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5244 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
0    [main] WARN  org.apache.spark.util.Utils  - Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp0s25)
3    [main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address
33   [main] INFO  org.apache.spark.SparkContext  - Running Spark version 2.4.0
169  [main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
253  [main] INFO  org.apache.spark.SparkContext  - Submitted application: Databus Client Converter
295  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: eisenbahnplatte
296  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: eisenbahnplatte
296  [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: 
296  [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: 
296  [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(eisenbahnplatte); groups with view permissions: Set(); users  with modify permissions: Set(eisenbahnplatte); groups with modify permissions: Set()
602  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'sparkDriver' on port 46019.
619  [main] INFO  org.apache.spark.SparkEnv  - Registering MapOutputTracker
632  [main] INFO  org.apache.spark.SparkEnv  - Registering BlockManagerMaster
634  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
634  [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - BlockManagerMasterEndpoint up
641  [main] INFO  org.apache.spark.storage.DiskBlockManager  - Created local directory at /tmp/blockmgr-56dc69b6-e697-43fa-a4dc-d16491b75eac
654  [main] INFO  org.apache.spark.storage.memory.MemoryStore  - MemoryStore started with capacity 1946.1 MB
664  [main] INFO  org.apache.spark.SparkEnv  - Registering OutputCommitCoordinator
717  [main] INFO  org.spark_project.jetty.util.log  - Logging initialized @3729ms
760  [main] INFO  org.spark_project.jetty.server.Server  - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
772  [main] INFO  org.spark_project.jetty.server.Server  - Started @3785ms
784  [main] INFO  org.spark_project.jetty.server.AbstractConnector  - Started ServerConnector@4c7e978c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
784  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'SparkUI' on port 4040.
800  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d23296{/jobs,null,AVAILABLE,@Spark}
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@54402c04{/jobs/json,null,AVAILABLE,@Spark}
801  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/jobs/job,null,AVAILABLE,@Spark}
802  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3f1a4795{/jobs/job/json,null,AVAILABLE,@Spark}
803  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/json,null,AVAILABLE,@Spark}
804  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@1dbd580{/stages/stage,null,AVAILABLE,@Spark}
806  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7fb48179{/stages/stage/json,null,AVAILABLE,@Spark}
806  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@201c3cda{/stages/pool,null,AVAILABLE,@Spark}
807  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4c86da0c{/stages/pool/json,null,AVAILABLE,@Spark}
808  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5d97caa4{/storage,null,AVAILABLE,@Spark}
808  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6732726{/storage/json,null,AVAILABLE,@Spark}
809  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@474821de{/storage/rdd,null,AVAILABLE,@Spark}
810  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@3d64c581{/storage/rdd/json,null,AVAILABLE,@Spark}
810  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5ec5ea63{/environment,null,AVAILABLE,@Spark}
811  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@4190bc8a{/environment/json,null,AVAILABLE,@Spark}
812  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@47d023b7{/executors,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@5c83ae01{/executors/json,null,AVAILABLE,@Spark}
813  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2d64c100{/executors/threadDump,null,AVAILABLE,@Spark}
814  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@69d45cca{/executors/threadDump/json,null,AVAILABLE,@Spark}
821  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@2fdf17dc{/static,null,AVAILABLE,@Spark}
822  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c269425{/,null,AVAILABLE,@Spark}
824  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@6e43ddd6{/api,null,AVAILABLE,@Spark}
824  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@655a01d8{/jobs/job/kill,null,AVAILABLE,@Spark}
825  [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@c29fe36{/stages/stage/kill,null,AVAILABLE,@Spark}
827  [main] INFO  org.apache.spark.ui.SparkUI  - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.104:4040
890  [main] INFO  org.apache.spark.executor.Executor  - Starting executor ID driver on host localhost
957  [main] INFO  org.apache.spark.util.Utils  - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39257.
957  [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService  - Server created on 192.168.0.104:39257
959  [main] INFO  org.apache.spark.storage.BlockManager  - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
979  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registering BlockManager BlockManagerId(driver, 192.168.0.104, 39257, None)
981  [dispatcher-event-loop-2] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint  - Registering block manager 192.168.0.104:39257 with 1946.1 MB RAM, BlockManagerId(driver, 192.168.0.104, 39257, None)
984  [main] INFO  org.apache.spark.storage.BlockManagerMaster  - Registered BlockManager BlockManagerId(driver, 192.168.0.104, 39257, None)
984  [main] INFO  org.apache.spark.storage.BlockManager  - Initialized BlockManager: BlockManagerId(driver, 192.168.0.104, 39257, None)
1138 [main] INFO  org.spark_project.jetty.server.handler.ContextHandler  - Started o.s.j.s.ServletContextHandler@7cfac39f{/metrics/json,null,AVAILABLE,@Spark}
1906 [main] WARN  org.apache.jena.arq.exec  - URI <http://www.w3.org/2001/XMLSchema#datetime> has no registered function factory
4197 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstücke 26 und 184"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstücke 26 und 184"
4233 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4250 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4275 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4281 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück: 77/1"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück: 77/1"
4289 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 6/10, 318/9"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 6/10, 318/9"
4349 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/Flurstück 109"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/Flurstück 109"
4352 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4358 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/"
4365 [main] ERROR org.apache.jena.sparql.expr.nodevalue.NodeFunctions  - Bad IRI: <http://data.rli.de/ontology/13"> Code: 4/UNWISE_CHARACTER in PATH: The character matches no grammar rules of URIs/IRIs. These characters are permitted in RDF URI References, XML system identifiers, and XML Schema anyURIs.: http://data.rli.de/ontology/13"
4838 [dispatcher-event-loop-5] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 0 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
5156 [dispatcher-event-loop-1] WARN  org.apache.spark.scheduler.TaskSetManager  - Stage 1 contains a task of very large size (168 KB). The maximum recommended task size is 100 KB.
